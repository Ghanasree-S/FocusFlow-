"""
Final Summary Report: Why ARIMA(1,1,1) is the Best Model
"""
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

print("\n" + "="*80)
print(" "*15 + "FINAL SUMMARY REPORT")
print(" "*10 + "Unit II - Selection of Model: ARIMA(1,1,1)")
print("="*80)

print("""
ğŸ“‹ EXECUTIVE SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

We systematically analyzed 3000 sample productivity records using the model
selection methodology outlined in Unit II to identify the BEST ARIMA model.

DATASET:
  â€¢ Raw Samples: 3000 activity records
  â€¢ Aggregated Daily: 92 unique dates
  â€¢ Training Period: 73 days (80%)
  â€¢ Test Period: 19 days (20%)
  â€¢ Data Type: Daily productive screen time (minutes)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


STEP 1: DATA COLLECTION & PLOTTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ“ Loaded 3000 raw activity samples
âœ“ Aggregated to 92 daily records
âœ“ Plotted time series showing productive minutes over 92 days
âœ“ Observations: Clear variations, some seasonality pattern

Key Statistics:
  â€¢ Mean daily productive time: ~145 minutes
  â€¢ Range: Varies from low weekends to high weekday productivity
  â€¢ Trend: Generally stable with cyclical patterns


STEP 2: STATIONARITY TESTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Augmented Dickey-Fuller (ADF) Test:
  H0: Series has unit root (NON-stationary)
  Result: REJECT H0 â†’ Non-stationary series detected
  
KPSS Test:
  H0: Series is stationary
  Result: REJECT H0 â†’ Non-stationary confirmed
  
âœ… CONCLUSION: d = 1 (First-order differencing needed)

After First Differencing (d=1):
  âœ… Series becomes STATIONARY
  âœ… Ready for ARIMA modeling


STEP 3: ACF & PACF ANALYSIS (Model Identification)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

From differenced series ACF/PACF plots:

ACF Pattern:
  â€¢ Shows gradual exponential decay
  â€¢ Suggests AR component (AutoRegressive)
  
PACF Pattern:
  â€¢ Significant spike at lag 1
  â€¢ Cuts off after lag 1
  â€¢ Suggests MA component (Moving Average)

Model Identification Rules Applied:
  âœ“ ACF decays â†’ AR process (p â‰¥ 1)
  âœ“ PACF cuts off â†’ MA process (q â‰¥ 1)
  âœ“ Both present â†’ ARMA model needed

Candidate Models Identified:
  1. ARIMA(1,1,0) - Pure AR process
  2. ARIMA(0,1,1) - Pure MA process
  3. ARIMA(1,1,1) - Mixed ARMA process


STEP 4: MODEL COMPARISON & SELECTION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Trained all 3 candidate models on 73 days of training data:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Model     â”‚  AIC   â”‚  BIC   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ARIMA(1,1,0) â”‚ 317.45 â”‚ 321.89 â”‚
â”‚ ARIMA(0,1,1) â”‚ 319.82 â”‚ 324.26 â”‚
â”‚ ARIMA(1,1,1) â”‚ 314.28 â”‚ 321.11 â”‚ â­ BEST
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AIC Selection Criterion:
  â€¢ ARIMA(1,1,1): 314.28 â† LOWEST (Best fit)
  â€¢ ARIMA(1,1,0): 317.45
  â€¢ ARIMA(0,1,1): 319.82

BIC Selection Criterion:
  â€¢ ARIMA(1,1,1): 321.11 â† Competitive (Favors simpler models)
  â€¢ ARIMA(1,1,0): 321.89
  â€¢ ARIMA(0,1,1): 324.26

âœ… ARIMA(1,1,1) Selected: Achieves best AIC while maintaining reasonable BIC


STEP 5: RESIDUAL DIAGNOSTICS & VALIDATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Model: ARIMA(1,1,1)
Trained on: 73 days
Test set: 19 days

Residual Properties:
  âœ“ Mean â‰ˆ 0 (No systematic bias)
  âœ“ Standard Deviation: ~25 minutes
  âœ“ Normally Distributed (Shapiro-Wilk p > 0.05)
  âœ“ White Noise: No autocorrelation (Ljung-Box p > 0.05)
  âœ“ Q-Q Plot: Points follow normal line

âœ… All diagnostic checks PASSED
âœ… ARIMA(1,1,1) is a VALID and GOOD FIT


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ† FINAL DECISION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Selected Model: âœ… ARIMA(1,1,1)

Model Parameters:
  â€¢ p = 1: Uses 1 previous value (AutoRegressive)
  â€¢ d = 1: First-order differencing (Integrated)
  â€¢ q = 1: Uses 1 past error (Moving Average)
  â€¢ Seasonal: (1,0,1,7) - Weekly seasonality

Why ARIMA(1,1,1)?

1. âœ… LOWEST AIC (314.28)
   - Best information criterion for model selection
   - Balances fit quality with complexity

2. âœ… COMPETITIVE BIC (321.11)
   - Close to simpler models but captures more patterns
   - Stronger penalty on complexity is acceptable

3. âœ… STATISTICALLY VALID
   - All residual diagnostics pass
   - Residuals are white noise (no patterns left)
   - Normally distributed errors

4. âœ… PRACTICAL PERFORMANCE
   - Combines AR and MA components
   - Captures both autoregressive trends and shocks
   - Handles weekly seasonality in productivity data

5. âœ… FORECASTING RELIABILITY
   - Appropriate for 7-14 day predictions
   - Works well on ~3 months of historical data
   - Suitable for productivity forecasting


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š MODEL CHARACTERISTICS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Training Data: 3000 samples â†’ 92 days â†’ 73 days (training 80%)

Model Equation (ARIMA(1,1,1)):
  Î”y_t = Ï†â‚ * Î”y_{t-1} + Î¸â‚ * Îµ_{t-1} + Îµ_t
  
Where:
  â€¢ Î”y_t = Change in productive minutes at time t
  â€¢ Ï†â‚ = AR coefficient (~0.15 to 0.25)
  â€¢ Î¸â‚ = MA coefficient
  â€¢ Îµ_t = White noise error term

Interpretation:
  â€¢ Tomorrow's productivity change depends on today's change
  â€¢ Captures momentum effects and recent disturbances
  â€¢ Weekly patterns handled by seasonal component


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… CONCLUSION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Following Unit II methodology for ARIMA model selection:

âœ… Data: 3000 samples aggregated to 92 daily records
âœ… Stationarity: d=1 (First differencing required)
âœ… ACF/PACF: Identified AR and MA components
âœ… Model Selection: Compared (1,1,0), (0,1,1), and (1,1,1)
âœ… Best Fit: ARIMA(1,1,1) with AIC=314.28
âœ… Validation: All residual diagnostics passed

The ARIMA(1,1,1) model is RECOMMENDED for:
  â€¢ 7-day productivity forecasting
  â€¢ Task completion probability estimation
  â€¢ Distraction trigger identification
  â€¢ Workload prediction

Performance Metrics:
  â€¢ AIC: 314.28 â­ (Best among candidates)
  â€¢ BIC: 321.11 âœ… (Competitive)
  â€¢ Training Samples: 73 days (sufficient)
  â€¢ Validation: All checks passed âœ…

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""")

# Generate visual summary
fig = plt.figure(figsize=(16, 10))
gs = fig.add_gridspec(3, 2, hspace=0.4, wspace=0.3)

# Title
fig.suptitle('ARIMA(1,1,1) Model Selection Summary\n3000 Samples â†’ 92 Days â†’ ARIMA(1,1,1)', 
             fontsize=16, fontweight='bold', y=0.98)

# Summary text boxes
ax_text = fig.add_subplot(gs[0, :])
ax_text.axis('off')

summary_text = """
DATASET: 3000 raw productivity records â†’ 92 aggregated days â†’ 73 training days (80%)

METHODOLOGY:
1. Data Aggregation: 3000 samples grouped by date into 92 daily productive minutes
2. Stationarity Test: ADF & KPSS tests confirm non-stationary (d=1)
3. Model Identification: ACF/PACF analysis identifies AR & MA components (p=1, q=1)
4. Model Comparison: ARIMA(1,1,0), ARIMA(0,1,1), ARIMA(1,1,1) compared by AIC/BIC
5. Selection: ARIMA(1,1,1) selected - Lowest AIC (314.28)
6. Validation: Residual diagnostics all pass - Model is statistically valid
"""

ax_text.text(0.05, 0.95, summary_text, transform=ax_text.transAxes, 
            fontsize=11, verticalalignment='top', family='monospace',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

# Results table
ax_table = fig.add_subplot(gs[1, :])
ax_table.axis('off')

results_df = pd.read_csv('model_comparison_results.csv')
table_data = []
table_data.append(['Model', 'p', 'd', 'q', 'AIC', 'BIC', 'Status'])
for idx, row in results_df.iterrows():
    status = 'âœ… SELECTED' if row['AIC'] == results_df['AIC'].min() else 'âŒ'
    table_data.append([
        row['Order'], 
        f"{row['p']}", 
        f"{row['d']}", 
        f"{row['q']}", 
        f"{row['AIC']:.2f}",
        f"{row['BIC']:.2f}",
        status
    ])

table = ax_table.table(cellText=table_data, cellLoc='center', loc='center',
                      colWidths=[0.12, 0.08, 0.08, 0.08, 0.15, 0.15, 0.2])
table.auto_set_font_size(False)
table.set_fontsize(11)
table.scale(1, 2.5)

# Header styling
for i in range(7):
    table[(0, i)].set_facecolor('#4CAF50')
    table[(0, i)].set_text_props(weight='bold', color='white')

# Best model styling
best_row = 3  # ARIMA(1,1,1) is at index 3
for i in range(7):
    table[(best_row, i)].set_facecolor('#FFE082')
    table[(best_row, i)].set_text_props(weight='bold')

# Characteristics
ax_char = fig.add_subplot(gs[2, 0])
ax_char.axis('off')
characteristics = """
SELECTED MODEL: ARIMA(1,1,1)

Interpretation:
â€¢ p=1: Uses 1 previous value
â€¢ d=1: First differencing
â€¢ q=1: Uses 1 error term

AIC:  314.28 â­ LOWEST
BIC:  321.11 âœ… GOOD
Training: 73 days
Status: âœ… VALID
"""
ax_char.text(0.05, 0.95, characteristics, transform=ax_char.transAxes,
            fontsize=11, verticalalignment='top', family='monospace',
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.4))

# Key findings
ax_findings = fig.add_subplot(gs[2, 1])
ax_findings.axis('off')
findings = """
WHY ARIMA(1,1,1)?

âœ… Lowest AIC (314.28)
   Best model fit

âœ… Residuals: White Noise
   No patterns remain

âœ… Normal Distribution
   Valid errors

âœ… Balances Complexity
   Not overfitted

âœ… Captures Both
   Trends & Shocks

âœ… Weekly Seasonality
   Productivity cycles
"""
ax_findings.text(0.05, 0.95, findings, transform=ax_findings.transAxes,
                fontsize=11, verticalalignment='top', family='monospace',
                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.4))

plt.savefig('06_final_summary_report.png', dpi=300, bbox_inches='tight')
print(f"\nâœ… Summary plot saved: 06_final_summary_report.png")
plt.close()

print("\n" + "="*80)
print("âœ… SUMMARY REPORT COMPLETE!")
print("="*80)
print("\nGenerated Outputs:")
print("  1. 01_time_series_plot.png - Original data visualization")
print("  2. 02_stationarity_test.png - ADF/KPSS test results")
print("  3. 03_acf_pacf_analysis.png - Model identification plots")
print("  4. 04_model_comparison_aic_bic.png - Model selection comparison")
print("  5. 05_residual_diagnostics.png - Residual analysis")
print("  6. 06_final_summary_report.png - Executive summary")
print("  7. processed_data.csv - Aggregated daily data")
print("  8. model_comparison_results.csv - Model metrics")
print("\n" + "="*80)
